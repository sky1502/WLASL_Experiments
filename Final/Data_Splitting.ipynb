{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b264bd0-7299-43b2-9630-e4f3f0d0610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The script allows to divide the WLASL dataset into sub-datasets. The division\n",
    "is made according to the order indicated in the JSON file. This file is made\n",
    "available by the authors of WLASL dataset.\n",
    "\n",
    "Usage: python k_gloss_splitting.py param1 param2\n",
    " - param1: path to the full dataset (e.g. ./WLASL_full/)\n",
    " - param2: number of glosses to be considered for the split (e.g. 2000)\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dade24d5-60c8-4a42-821d-96ea9cc50489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "PATH_JSON = r'../json/WLASL_v0.3.json'\n",
    "path_dataset = r'../video_data/videos/'\n",
    "glosses = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fa43031-4e69-4988-8efe-d827b553e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_processing(glosses, path_k_glosses_dir, path_dataset):\n",
    "    # read the json as a list of dictionaries\n",
    "    wlasl_json = read_json(PATH_JSON)\n",
    "    splitted_videos = splitting_train_val_test(wlasl_json, glosses)\n",
    "    make_target_dirs(wlasl_json, glosses, path_k_glosses_dir)\n",
    "    save_in_dirs(path_dataset, path_k_glosses_dir, splitted_videos)\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        wlasl_json = json.load(f)\n",
    "    return wlasl_json\n",
    "\n",
    "def splitting_train_val_test(json_file, glosses):\n",
    "    print('[log] > Splitting videos in train, val and test ...')\n",
    "    videos_dict = {}\n",
    "    for k, gloss in tqdm(enumerate(json_file)):\n",
    "        if k < glosses:\n",
    "            videos = gloss['instances']\n",
    "            for video in videos:\n",
    "                video_id = video['video_id']\n",
    "                target_dir = video['split']\n",
    "                gloss_name = gloss['gloss']\n",
    "                videos_dict[video_id] = (target_dir, gloss_name)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return videos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1baaab97-772b-4464-a32d-d635af3c4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_dirs(json_file, glosses, path_k_glosses_dir):\n",
    "    if os.path.isdir('./' + path_k_glosses_dir):\n",
    "        shutil.rmtree(path_k_glosses_dir)\n",
    "    os.mkdir(path_k_glosses_dir)\n",
    "    # create the train, val and test dirs\n",
    "    os.mkdir(path_k_glosses_dir + 'train')\n",
    "    os.mkdir(path_k_glosses_dir + 'val')\n",
    "    os.mkdir(path_k_glosses_dir + 'test')\n",
    "\n",
    "    print('\\n[log] > Creating dirs ...')\n",
    "    for k, gloss in tqdm(enumerate(json_file)):\n",
    "        if k < glosses:\n",
    "            os.mkdir(path_k_glosses_dir + 'train/' + gloss['gloss'])\n",
    "            os.mkdir(path_k_glosses_dir + 'val/' + gloss['gloss'])\n",
    "            os.mkdir(path_k_glosses_dir + 'test/' + gloss['gloss'])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "def save_in_dirs(path_dataset, path_k_glosses_dir, videos):\n",
    "    print('\\n[log] > Copying videos in their own dir ...')\n",
    "    for video_id, data in tqdm(videos.items()):\n",
    "        source_url = path_dataset + video_id + '.mp4'\n",
    "        if not os.path.exists('{}'.format(source_url)):\n",
    "            continue\n",
    "        destination_url = path_k_glosses_dir + data[0] + '/' + data[1] + '/'\n",
    "        shutil.copy(source_url, destination_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0c959e6-7f6e-46af-acb3-45ed2122f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_info(path_k_glosses_dir):\n",
    "    print_entries(path_k_glosses_dir)\n",
    "    print_videos_info(path_k_glosses_dir)\n",
    "\n",
    "def print_entries(path_root):\n",
    "    path_train = path_root + 'train/'\n",
    "    path_val = path_root + 'val/'\n",
    "    path_test = path_root + 'test/'\n",
    "\n",
    "    n_tot = sum([len(files) for _, _, files in os.walk(path_root)])\n",
    "    n_train = sum([len(files) for _, _, files in os.walk(path_train)])\n",
    "    n_val = sum([len(files) for _, _, files in os.walk(path_val)])\n",
    "    n_test = sum([len(files) for _, _, files in os.walk(path_test)])\n",
    "\n",
    "    print('\\n[log] > Dataset summary:')\n",
    "    print(f'Total videos: {n_tot}')\n",
    "    print(f'Videos in train: {n_train} - {(n_train / n_tot * 100):,.0f}%')\n",
    "    print(f'Videos in val:   {n_val} - {(n_val / n_tot * 100):,.0f}%')\n",
    "    print(f'Videos in test:  {n_test} - {(n_test / n_tot * 100):,.0f}%')\n",
    "\n",
    "\n",
    "def print_videos_info(path_root):\n",
    "    videos = get_videos_path(path_root)\n",
    "    info = get_videos_info(videos)\n",
    "    print('\\n[log] > Dataset info:')\n",
    "    print(\n",
    "        f'The video {info[0][0]} has the MIN length: {info[0][1]} - '\n",
    "        f'Total frames: {info[0][2]}'\n",
    "    )\n",
    "    print(\n",
    "        f'The video {info[-1][0]} has the MAX length: {info[-1][1]} - '\n",
    "        f'Total frames: {info[-1][2]}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1379520c-f8af-4917-8133-8f8c5017f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_path(path_root):\n",
    "    # get videos path\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(os.path.relpath(path_root)):\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(root, file))\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_videos_info(videos):\n",
    "    print('\\n[log] > Retrieving videos metadata ...')\n",
    "    lengths = [get_meta_data(vid_path) for vid_path in tqdm(videos)]\n",
    "    return sorted(lengths, key=lambda x: x[1])\n",
    "    \n",
    "def get_meta_data(file_path):\n",
    "    video_cap = cv2.VideoCapture(file_path)\n",
    "    fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    video_cap.release()\n",
    "    file_name = os.path.basename(os.path.normpath(file_path))\n",
    "    return file_name, duration, frame_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b12156b-5552-4826-a464-24a4f2ecfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        if not 1 <= glosses <= 2000:\n",
    "            raise ValueError('\\nInsert an integer: 1~2000')\n",
    "        path_k_glosses_dir = r'../video_data/WLASL_' + str(glosses) + '/'\n",
    "        print('[log] > START DATASET PROCESSING ...\\n')\n",
    "        dataset_processing(glosses, path_k_glosses_dir, path_dataset)\n",
    "        show_info(path_k_glosses_dir)\n",
    "        print('\\n[log] > DONE!')\n",
    "    except ValueError:\n",
    "        print('Insert an integer: 1~2000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a4e8251-decb-42f4-b3bb-7c8f5b2913eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] > START DATASET PROCESSING ...\n",
      "\n",
      "[log] > Splitting videos in train, val and test ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 370816.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[log] > Creating dirs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1093.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[log] > Copying videos in their own dir ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21083/21083 [00:36<00:00, 572.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[log] > Dataset summary:\n",
      "Total videos: 19049\n",
      "Videos in train: 12859 - 68%\n",
      "Videos in val:   3670 - 19%\n",
      "Videos in test:  2520 - 13%\n",
      "\n",
      "[log] > Retrieving videos metadata ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19049/19049 [01:31<00:00, 207.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[log] > Dataset info:\n",
      "The video 15144.mp4 has the MIN length: 0.3003003003003003 - Total frames: 9\n",
      "The video 57628.mp4 has the MAX length: 8.125 - Total frames: 195\n",
      "\n",
      "[log] > DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a341a2-fc83-4073-a8b6-5e5e55275c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
